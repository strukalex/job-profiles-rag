{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Implementation of Graph RAG for Job Profile Analysis Using Local Ollama Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a complete Graph RAG implementation for analyzing job profile documents using local Ollama models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU langchain langchain_community langchain-experimental neo4j pyvis ollama python-dotenv\n",
    "# !ollama pull llama3.1  # 8B parameter model recommended\n",
    "# !ollama pull nomic-embed-text  # Embedding model\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TESTING=False           # Set to True to run with toy data\n",
    "RUN_IN_BATCH=True       # If False, will try to run all chunks at once to get entity connections, otherwise will save after each one\n",
    "USE_OLLAMA=False         # Whether to use local Ollama or Azure API\n",
    "LIMIT_CHUNKS=1       # Set to a number to limit the number of chunk to be processed\n",
    "CHUNK_SIZE=1000          \n",
    "csvPath=\"../data/job profiles/2025-02-07_profiles.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "import pandas as pd\n",
    "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
    "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
    "from mistral_common.protocol.instruct.messages import UserMessage\n",
    "\n",
    "class JobProfile(BaseModel):\n",
    "    title: str = Field(description=\"Official job title\")\n",
    "    classifications: List[str] = Field(description=\"Classification codes\")\n",
    "    organizations: List[str] \n",
    "    behavioural_competencies: List[str]\n",
    "    education: List[str] = Field(description=\"Education requirements\")\n",
    "    job_experience: List[str]\n",
    "    knowledge_skills_abilities: List[str]\n",
    "    security_screenings: List[str]\n",
    "    accountabilities: List[str]\n",
    "    role_type: Optional[str] = Field(description=\"Role category\")\n",
    "    scopes: Optional[List[str]] = Field(description=\"Areas of responsibility\")\n",
    "    professional_registration: Optional[List[str]]\n",
    "\n",
    "if not TESTING:\n",
    "    from notebooks.utils import get_job_profile_documents\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "    documents=get_job_profile_documents(csvPath, include_org_class_sections=False)\n",
    "    tokenizer = MistralTokenizer.from_model(\"mistral-small\", strict=True)\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=200,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"â€¢\", \" \", \"\"],\n",
    "        length_function=lambda text: len(tokenizer.encode_chat_completion(\n",
    "            ChatCompletionRequest(\n",
    "                messages=[\n",
    "                    UserMessage(content=text)\n",
    "                ],\n",
    "                model=\"mistral-small-latest\"\n",
    "            )\n",
    "        ).tokens)\n",
    "    )\n",
    "    \n",
    "    chunks = splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIMIT_CHUNKS is not None:\n",
    "    chunks=chunks[0:LIMIT_CHUNKS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'version', 'title', 'number', 'overview', 'program_overview',\n",
       "       'state', 'type', 'behavioural_competencies', 'accountabilities',\n",
       "       'education', 'job_experience', 'professional_registration_requirements',\n",
       "       'preferences', 'knowledge_skills_abilities', 'willingness_statements',\n",
       "       'optional_requirements', 'security_screenings', 'all_reports_to',\n",
       "       'context', 'is_archived', 'valid_from', 'valid_to', 'views', 'role',\n",
       "       'role_type', 'created_at', 'updated_at', 'published_at',\n",
       "       'classifications', 'organizations', 'scopes', 'job_families', 'streams',\n",
       "       'reports_to'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvPath=\"../data/job profiles/2025-02-07_profiles.csv\"\n",
    "df=pd.read_csv(csvPath)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "# import logging\n",
    "\n",
    "# Enable verbose logging for all components\n",
    "set_debug(True)\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO) # DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neo4j Graph Database Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize db connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '69116869CB35145331EE2540ACCB41CE6769FA0EF563941B7EF46E8944A02587', 'name': 'neo4j', 'creationDate': '2025-02-23T22:56:33.286Z'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_neo4j import Neo4jGraph, GraphCypherQAChain\n",
    "import os\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"your_password\"\n",
    "\n",
    "graph = Neo4jGraph()\n",
    "print(graph.query(\"CALL db.info()\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load structured data into neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from notebooks.utils import get_clean_job_profiles_df\n",
    "\n",
    "\n",
    "df = get_clean_job_profiles_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                                                       13\n",
      "version                                                                                   1\n",
      "title                                                                       Licensing Clerk\n",
      "number                                                                                  192\n",
      "overview                                  To process all new license applications or ren...\n",
      "program_overview                                                                        NaN\n",
      "state                                                                             PUBLISHED\n",
      "type                                                                              CORPORATE\n",
      "behavioural_competencies                  [Decisive insight, Information seeking, Concer...\n",
      "accountabilities                          [Reviews licensing applications to ensure they...\n",
      "education                                 [Certificate or coursework and 6 months relate...\n",
      "job_experience                            [Experience applying regulations or policies.,...\n",
      "professional_registration_requirements                                                   []\n",
      "preferences                                                                              []\n",
      "knowledge_skills_abilities                [A strong attention to detail., Ability to acc...\n",
      "willingness_statements                                                                   []\n",
      "optional_requirements                                                                    []\n",
      "security_screenings                       [Successful completion of security screening r...\n",
      "all_reports_to                                                                        False\n",
      "context                                   <p>The job profile can be one of several Licen...\n",
      "is_archived                                                                           False\n",
      "valid_from                                                       2024-07-31 17:35:40.808000\n",
      "valid_to                                                                                NaT\n",
      "views                                                                                     3\n",
      "role                                                           [Operational/Administration]\n",
      "role_type                                                          [Individual Contributor]\n",
      "created_at                                                       2024-07-31 17:35:40.821000\n",
      "updated_at                                                       2025-01-15 23:09:25.520000\n",
      "published_at                                                                            NaT\n",
      "classifications                                                   [CLBC Clerk R9, Clerk R9]\n",
      "organizations                             [Agriculture and Food (AGR), Attorney General ...\n",
      "scopes                                                                            [Program]\n",
      "job_families                                                      [Administrative Services]\n",
      "streams                                              [Administrative Support, Adjudication]\n",
      "reports_to                                [Band 1 MS, Band 2 MS, Band 3 MS, Band 4 MS, B...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_job_profiles_to_neo4j(df, uri, username, password):\n",
    "    \"\"\"\n",
    "    Load job profiles data from DataFrame to Neo4j\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame containing job profiles\n",
    "    uri: Neo4j connection URI (e.g., \"neo4j://localhost:7687\")\n",
    "    username: Neo4j username\n",
    "    password: Neo4j password\n",
    "    \"\"\"\n",
    "    # Connect to Neo4j\n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        print(\"Deleting all existing data...\")\n",
    "        session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "        \n",
    "        # Create constraints and indexes for better performance\n",
    "        session.run(\"CREATE CONSTRAINT job_profile_id IF NOT EXISTS FOR (j:JobProfile) REQUIRE j.id IS UNIQUE\")\n",
    "        session.run(\"CREATE INDEX job_profile_title IF NOT EXISTS FOR (j:JobProfile) ON (j.title)\")\n",
    "        \n",
    "        # Create indexes for related nodes\n",
    "        for label in [\"BehavioralCompetency\", \"Accountability\", \"Education\", \"Experience\", \n",
    "                     \"Registration\", \"Preference\", \"KSA\", \"WillingnessStatement\", \n",
    "                     \"OptionalRequirement\", \"SecurityScreening\", \"Role\", \"RoleType\", \n",
    "                     \"Classification\", \"Organization\", \"Scope\", \"JobFamily\", \"Stream\", \"ReportsTo\"]:\n",
    "            session.run(f\"CREATE INDEX {label.lower()}_name IF NOT EXISTS FOR (n:{label}) ON (n.name)\")\n",
    "        \n",
    "        # Process each job profile\n",
    "        # i=0\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Loading job profiles\"):\n",
    "            # i+=1\n",
    "            # if i>10:\n",
    "            #     break\n",
    "            # print('processing: ', i, '/', len(df))\n",
    "            \n",
    "            # Create job profile node\n",
    "            create_job_profile_query = \"\"\"\n",
    "            MERGE (j:JobProfile {id: $id})\n",
    "            SET j.version = $version,\n",
    "                j.title = $title,\n",
    "                j.number = $number,\n",
    "                j.overview = $overview,\n",
    "                j.program_overview = $program_overview,\n",
    "                j.state = $state,\n",
    "                j.type = $type,\n",
    "                j.context = $context,\n",
    "                j.is_archived = $is_archived,\n",
    "                j.all_reports_to = $all_reports_to,\n",
    "                j.valid_from = datetime($valid_from),\n",
    "                j.valid_to = CASE WHEN $valid_to IS NULL THEN NULL ELSE datetime($valid_to) END,\n",
    "                j.views = $views,\n",
    "                j.created_at = datetime($created_at),\n",
    "                j.updated_at = datetime($updated_at),\n",
    "                j.published_at = CASE WHEN $published_at IS NULL THEN NULL ELSE datetime($published_at) END\n",
    "            RETURN j\n",
    "            \"\"\"\n",
    "            \n",
    "            # Convert timestamps to ISO format for Neo4j\n",
    "            valid_from = row['valid_from'].isoformat() if pd.notna(row.get('valid_from')) else None\n",
    "            valid_to = row['valid_to'].isoformat() if pd.notna(row.get('valid_to')) else None\n",
    "            created_at = row['created_at'].isoformat() if pd.notna(row.get('created_at')) else None\n",
    "            updated_at = row['updated_at'].isoformat() if pd.notna(row.get('updated_at')) else None\n",
    "            published_at = row['published_at'].isoformat() if pd.notna(row.get('published_at')) else None\n",
    "            \n",
    "            # Create job profile node\n",
    "            job_profile = session.run(\n",
    "                create_job_profile_query,\n",
    "                id=int(row['id']),\n",
    "                version=int(row['version']) if pd.notna(row.get('version')) else None,\n",
    "                title=row['title'] if pd.notna(row.get('title')) else None,\n",
    "                number=int(row['number']) if pd.notna(row.get('number')) else None,\n",
    "                overview=row['overview'] if pd.notna(row.get('overview')) else None,\n",
    "                program_overview=row['program_overview'] if pd.notna(row.get('program_overview')) else None,\n",
    "                state=row['state'] if pd.notna(row.get('state')) else None,\n",
    "                type=row['type'] if pd.notna(row.get('type')) else None,\n",
    "                context=row['context'] if pd.notna(row.get('context')) else None,\n",
    "                is_archived=bool(row['is_archived']) if pd.notna(row.get('is_archived')) else False,\n",
    "                all_reports_to=bool(row['all_reports_to']) if pd.notna(row.get('all_reports_to')) else False,\n",
    "                valid_from=valid_from,\n",
    "                valid_to=valid_to,\n",
    "                views=int(row['views']) if pd.notna(row.get('views')) else 0,\n",
    "                created_at=created_at,\n",
    "                updated_at=updated_at,\n",
    "                published_at=published_at\n",
    "            ).single()\n",
    "            \n",
    "            # Create relationships for list fields\n",
    "            create_relationships(session, row['id'], 'behavioural_competencies', 'BehavioralCompetency', 'HAS_COMPETENCY', row)\n",
    "            create_relationships(session, row['id'], 'accountabilities', 'Accountability', 'HAS_ACCOUNTABILITY', row)\n",
    "            create_relationships(session, row['id'], 'education', 'Education', 'REQUIRES_EDUCATION', row)\n",
    "            create_relationships(session, row['id'], 'job_experience', 'Experience', 'REQUIRES_EXPERIENCE', row)\n",
    "            create_relationships(session, row['id'], 'professional_registration_requirements', 'Registration', 'REQUIRES_REGISTRATION', row)\n",
    "            create_relationships(session, row['id'], 'preferences', 'Preference', 'HAS_PREFERENCE', row)\n",
    "            create_relationships(session, row['id'], 'knowledge_skills_abilities', 'KSA', 'REQUIRES_KSA', row)\n",
    "            create_relationships(session, row['id'], 'willingness_statements', 'WillingnessStatement', 'HAS_WILLINGNESS', row)\n",
    "            create_relationships(session, row['id'], 'optional_requirements', 'OptionalRequirement', 'HAS_OPTIONAL_REQUIREMENT', row)\n",
    "            create_relationships(session, row['id'], 'security_screenings', 'SecurityScreening', 'REQUIRES_SCREENING', row)\n",
    "            create_relationships(session, row['id'], 'role', 'Role', 'HAS_ROLE', row)\n",
    "            create_relationships(session, row['id'], 'role_type', 'RoleType', 'HAS_ROLE_TYPE', row)\n",
    "            create_relationships(session, row['id'], 'classifications', 'Classification', 'HAS_CLASSIFICATION', row)\n",
    "            create_relationships(session, row['id'], 'organizations', 'Organization', 'BELONGS_TO_ORGANIZATION', row)\n",
    "            create_relationships(session, row['id'], 'scopes', 'Scope', 'HAS_SCOPE', row)\n",
    "            create_relationships(session, row['id'], 'job_families', 'JobFamily', 'BELONGS_TO_JOB_FAMILY', row)\n",
    "            create_relationships(session, row['id'], 'streams', 'Stream', 'BELONGS_TO_STREAM', row)\n",
    "            create_relationships(session, row['id'], 'reports_to', 'ReportsTo', 'REPORTS_TO', row)\n",
    "    \n",
    "    driver.close()\n",
    "    print(\"Data loading completed successfully!\")\n",
    "\n",
    "def create_relationships(session, job_id, field_name, node_label, relationship_type, row):\n",
    "    \"\"\"Create relationships between job profile and related entities\"\"\"\n",
    "    if isinstance(row.get(field_name), list) and len(row.get(field_name)) > 0:\n",
    "        for item in row[field_name]:\n",
    "            query = f\"\"\"\n",
    "            MATCH (j:JobProfile {{id: $job_id}})\n",
    "            MERGE (n:{node_label} {{name: $name}})\n",
    "            MERGE (j)-[r:{relationship_type}]->(n)\n",
    "            RETURN j, n\n",
    "            \"\"\"\n",
    "            session.run(query, job_id=int(job_id), name=item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all existing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading job profiles: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 502/502 [02:19<00:00,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "URI = \"neo4j://localhost:7687\"\n",
    "USERNAME = \"neo4j\"\n",
    "PASSWORD = \"your_password\"\n",
    "\n",
    "# Load data to Neo4j\n",
    "load_job_profiles_to_neo4j(df, URI, USERNAME, PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nodes': [{'name': 'Organization', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'RoleType', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'JobFamily', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'Document', 'indexes': ['embedding'], 'constraints': []},\n",
       "   {'name': 'JobProfile',\n",
       "    'indexes': ['title'],\n",
       "    'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "   {'name': 'OptionalRequirement', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'Role', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'Experience', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'Scope', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'Education', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'Preference', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': '__Entity__',\n",
       "    'indexes': [],\n",
       "    'constraints': [\"Constraint( id=4, name='constraint_907a464e', type='UNIQUENESS', schema=(:__Entity__ {id}), ownedIndex=3 )\"]},\n",
       "   {'name': 'Registration', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'Classification', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'Accountability', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'KSA', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'ReportsTo', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'Stream', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'BehavioralCompetency', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'SecurityScreening', 'indexes': ['name'], 'constraints': []},\n",
       "   {'name': 'WillingnessStatement', 'indexes': ['name'], 'constraints': []}],\n",
       "  'relationships': [({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'HAS_ROLE_TYPE',\n",
       "    {'name': 'RoleType', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'BELONGS_TO_JOB_FAMILY',\n",
       "    {'name': 'JobFamily', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'HAS_PREFERENCE',\n",
       "    {'name': 'Preference', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'HAS_CLASSIFICATION',\n",
       "    {'name': 'Classification', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'REQUIRES_REGISTRATION',\n",
       "    {'name': 'Registration', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'HAS_ACCOUNTABILITY',\n",
       "    {'name': 'Accountability', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'BELONGS_TO_STREAM',\n",
       "    {'name': 'Stream', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'REPORTS_TO',\n",
       "    {'name': 'ReportsTo', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'HAS_WILLINGNESS',\n",
       "    {'name': 'WillingnessStatement', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'REQUIRES_EDUCATION',\n",
       "    {'name': 'Education', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'HAS_SCOPE',\n",
       "    {'name': 'Scope', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'REQUIRES_SCREENING',\n",
       "    {'name': 'SecurityScreening', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'HAS_ROLE',\n",
       "    {'name': 'Role', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'BELONGS_TO_ORGANIZATION',\n",
       "    {'name': 'Organization', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'REQUIRES_KSA',\n",
       "    {'name': 'KSA', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'REQUIRES_EXPERIENCE',\n",
       "    {'name': 'Experience', 'indexes': ['name'], 'constraints': []}),\n",
       "   ({'name': 'JobProfile',\n",
       "     'indexes': ['title'],\n",
       "     'constraints': [\"Constraint( id=7, name='job_profile_id', type='UNIQUENESS', schema=(:JobProfile {id}), ownedIndex=6 )\"]},\n",
       "    'HAS_COMPETENCY',\n",
       "    {'name': 'BehavioralCompetency',\n",
       "     'indexes': ['name'],\n",
       "     'constraints': []})]}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\"CALL db.schema.visualization()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Classification {name: STRING}\n",
      "Organization {name: STRING}\n",
      "Education {name: STRING}\n",
      "Experience {name: STRING}\n",
      "SecurityScreening {name: STRING}\n",
      "Accountability {name: STRING}\n",
      "Role {name: STRING}\n",
      "Preference {name: STRING}\n",
      "JobProfile {views: INTEGER, updated_at: DATE_TIME, context: STRING, title: STRING, created_at: DATE_TIME, number: INTEGER, all_reports_to: BOOLEAN, valid_from: DATE_TIME, id: INTEGER, type: STRING, is_archived: BOOLEAN, version: INTEGER, overview: STRING, state: STRING, published_at: DATE_TIME, program_overview: STRING}\n",
      "BehavioralCompetency {name: STRING}\n",
      "Registration {name: STRING}\n",
      "KSA {name: STRING}\n",
      "WillingnessStatement {name: STRING}\n",
      "RoleType {name: STRING}\n",
      "Scope {name: STRING}\n",
      "JobFamily {name: STRING}\n",
      "Stream {name: STRING}\n",
      "ReportsTo {name: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:JobProfile)-[:HAS_ACCOUNTABILITY]->(:Accountability)\n",
      "(:JobProfile)-[:HAS_CLASSIFICATION]->(:Classification)\n",
      "(:JobProfile)-[:BELONGS_TO_ORGANIZATION]->(:Organization)\n",
      "(:JobProfile)-[:HAS_ROLE]->(:Role)\n",
      "(:JobProfile)-[:REQUIRES_EXPERIENCE]->(:Experience)\n",
      "(:JobProfile)-[:HAS_COMPETENCY]->(:BehavioralCompetency)\n",
      "(:JobProfile)-[:REQUIRES_EDUCATION]->(:Education)\n",
      "(:JobProfile)-[:REQUIRES_KSA]->(:KSA)\n",
      "(:JobProfile)-[:REQUIRES_SCREENING]->(:SecurityScreening)\n",
      "(:JobProfile)-[:HAS_ROLE_TYPE]->(:RoleType)\n",
      "(:JobProfile)-[:HAS_SCOPE]->(:Scope)\n",
      "(:JobProfile)-[:BELONGS_TO_JOB_FAMILY]->(:JobFamily)\n",
      "(:JobProfile)-[:BELONGS_TO_STREAM]->(:Stream)\n",
      "(:JobProfile)-[:REPORTS_TO]->(:ReportsTo)\n",
      "(:JobProfile)-[:HAS_WILLINGNESS]->(:WillingnessStatement)\n",
      "(:JobProfile)-[:REQUIRES_REGISTRATION]->(:Registration)\n",
      "(:JobProfile)-[:HAS_PREFERENCE]->(:Preference)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationships Found: 38206\n",
      "Relationship Types: ['REQUIRES_EXPERIENCE', 'REQUIRES_KSA', 'REQUIRES_SCREENING', 'HAS_ROLE', 'HAS_ROLE_TYPE', 'HAS_CLASSIFICATION', 'BELONGS_TO_ORGANIZATION', 'HAS_SCOPE', 'BELONGS_TO_JOB_FAMILY', 'BELONGS_TO_STREAM', 'REPORTS_TO', 'HAS_COMPETENCY', 'HAS_ACCOUNTABILITY', 'REQUIRES_EDUCATION', 'HAS_WILLINGNESS', 'REQUIRES_REGISTRATION', 'HAS_PREFERENCE']\n"
     ]
    }
   ],
   "source": [
    "# Check relationship count in database\n",
    "result = graph.query(\"\"\"\n",
    "    MATCH ()-[r]->() \n",
    "    RETURN count(r) AS relationship_count,\n",
    "           collect(distinct type(r)) AS relationship_types\n",
    "\"\"\")\n",
    "print(f\"Relationships Found: {result[0]['relationship_count']}\")\n",
    "print(f\"Relationship Types: {result[0]['relationship_types']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vector index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorstore generation from existing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to existing Neo4jGraph initialization\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n",
    "\n",
    "# his method pulls relevant text information from the database, and calculates and stores the text embeddings back to the database.\n",
    "vector_store = Neo4jVector.from_existing_graph(\n",
    "    embedding=embeddings,\n",
    "    url=os.environ[\"NEO4J_URI\"],\n",
    "    username=os.environ[\"NEO4J_USERNAME\"],\n",
    "    password=os.environ[\"NEO4J_PASSWORD\"],\n",
    "    index_name=\"document_embeddings\",\n",
    "    embedding_node_property=\"embedding\",\n",
    "    node_label=\"Entity\", # Generic label for all nodes\n",
    "    text_node_properties=[\"name\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 5, 'name': 'document_embeddings', 'state': 'ONLINE', 'populationPercent': 100.0, 'type': 'VECTOR', 'entityType': 'NODE', 'labelsOrTypes': ['Document'], 'properties': ['embedding'], 'indexProvider': 'vector-2.0', 'owningConstraint': None, 'lastRead': neo4j.time.DateTime(2025, 2, 24, 7, 49, 10, 9000000, tzinfo=<UTC>), 'readCount': 2}]\n"
     ]
    }
   ],
   "source": [
    "index_info = vector_store.query(\"\"\"\n",
    "SHOW INDEXES \n",
    "WHERE name = 'document_embeddings'\n",
    "\"\"\")\n",
    "print(index_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "results = vector_store.similarity_search(\"Public Safety & Sol General (PSSG)\", k=2)\n",
    "for doc in results:\n",
    "    print('==== DOC ====')\n",
    "    pprint(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\n",
    "\n",
    "# Initialize with updated model naming format\n",
    "\n",
    "llm = AzureAIChatCompletionsModel(\n",
    "            endpoint=os.getenv('AZURE_ENDPOINT'),\n",
    "            credential=os.getenv('AZURE_API_KEY'),\n",
    "            model_name=\"Mistral-small\",\n",
    "            api_version=\"2024-05-01-preview\",\n",
    "            model_kwargs={\"max_tokens\": 4000},\n",
    "            \n",
    "            temperature=0.5,\n",
    "            top_p=0.4\n",
    "        )\n",
    "graph_transformer = LLMGraphTransformer(llm=llm)\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    llm=llm, graph=graph, verbose=True, allow_dangerous_requests=True,\n",
    "    # exclude_types=['Document']\n",
    "    # validate_cypher=True,  # New critical parameter\n",
    "    # schema_constraints={\n",
    "    #     \"Jobprofile\": {\"identifier\": \"id\"},  # Force 'id' usage\n",
    "    #     \"Document\": {\"identifier\": \"title\"}\n",
    "    # }\n",
    ")\n",
    "chain.invoke({\"query\": \"What organizations does the 'Licensing Clerk' profile belong to? Ensure title is treated as 'id' instead of 'title'\"})\n",
    "# use backticks for labels containing spaces: e.g. MATCH (jt:`Job Title` ========== \\n "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
