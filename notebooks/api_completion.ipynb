{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from openai import OpenAI  # Changed import\n",
    "import httpx\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings and vectorstore (unchanged)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"../job_profiles_db2\",\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"job_profiles\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve context documents (unchanged)\n",
    "query = \"Which job profiles have administration related skills?\"\n",
    "context_docs = vectorstore.similarity_search(query, k=3)\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in context_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = f\"\"\"System: You're an expert in answering questions about a library of job profiles. Use this context:\n",
    "{context}\n",
    "\n",
    "User: {query}\n",
    "Assistant: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list',\n",
       " 'data': [{'id': 'job-profile-rag',\n",
       "   'object': 'model',\n",
       "   'created': 1739562390,\n",
       "   'owned_by': 'your-company',\n",
       "   'capabilities': {'completions': True, 'chat_completions': True}}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get('http://localhost:8000/v1/models')\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: All three job profiles have administration related skills.\n",
      "\n",
      "The Training Administrator coordinates financial and administrative processes for a training program, enters training data into HRIS and training database, and runs reports on learning activities.\n",
      "\n",
      "The Program Assistant Supervisory provides office administrative, secretarial, and financial support services, and coordinates the day-to-day priorities of the manager.\n",
      "\n",
      "Industrial Relations Officers (IROs) also have administrative responsibilities, such as writing investigation reports consistent with legal requirements and conducting representation votes for the Labour Relations Board. Additionally, they mentor and train Employment Standards Officers on investigative techniques and best practices for investigations, which involves administrative tasks related to training and development.\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client with local endpoint\n",
    "import socket\n",
    "server = f'{socket.gethostname()}.local'\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:1234/v1\",  # Use IPv4 loopback\n",
    "    api_key=\"None\",  # Can be any string if your local endpoint doesn't require auth\n",
    ")\n",
    "\n",
    "# Create and send request using OpenAI format\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-r1-distill-qwen-1.5b\",  # Model name expected by your local endpoint\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You're an expert in answering questions about a library of job profiles.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {query}\"}\n",
    "    ],\n",
    "    max_tokens=300,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Process response\n",
    "if response and response.choices:\n",
    "    print(\"Response:\", response.choices[0].message.content)\n",
    "else:\n",
    "    print(\"No response received\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job-profiles-rag",
   "language": "python",
   "name": "job-profiles-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
