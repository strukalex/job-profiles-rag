{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents adding: 525\n",
      "creating vector store..\n",
      "Processing batch 1, size: 10\n",
      "Current document count: 10\n",
      "Processing batch 2, size: 10\n",
      "Current document count: 20\n",
      "Processing batch 3, size: 10\n",
      "Current document count: 30\n",
      "Processing batch 4, size: 10\n",
      "Current document count: 40\n",
      "Processing batch 5, size: 10\n",
      "Current document count: 50\n",
      "Processing batch 6, size: 10\n",
      "Current document count: 60\n",
      "Processing batch 7, size: 10\n",
      "Current document count: 70\n",
      "Processing batch 8, size: 10\n",
      "Current document count: 80\n",
      "Processing batch 9, size: 10\n",
      "Current document count: 90\n",
      "Processing batch 10, size: 10\n",
      "Current document count: 100\n",
      "Processing batch 11, size: 10\n",
      "Current document count: 110\n",
      "Processing batch 12, size: 10\n",
      "Current document count: 120\n",
      "Processing batch 13, size: 10\n",
      "Current document count: 130\n",
      "Processing batch 14, size: 10\n",
      "Current document count: 140\n",
      "Processing batch 15, size: 10\n",
      "Current document count: 150\n",
      "Processing batch 16, size: 10\n",
      "Current document count: 160\n",
      "Processing batch 17, size: 10\n",
      "Current document count: 170\n",
      "Processing batch 18, size: 10\n",
      "Current document count: 180\n",
      "Processing batch 19, size: 10\n",
      "Current document count: 190\n",
      "Processing batch 20, size: 10\n",
      "Current document count: 200\n",
      "Processing batch 21, size: 10\n",
      "Current document count: 210\n",
      "Processing batch 22, size: 10\n",
      "Current document count: 220\n",
      "Processing batch 23, size: 10\n",
      "Current document count: 230\n",
      "Processing batch 24, size: 10\n",
      "Current document count: 240\n",
      "Processing batch 25, size: 10\n",
      "Current document count: 250\n",
      "Processing batch 26, size: 10\n",
      "Current document count: 260\n",
      "Processing batch 27, size: 10\n",
      "Current document count: 270\n",
      "Processing batch 28, size: 10\n",
      "Current document count: 280\n",
      "Processing batch 29, size: 10\n",
      "Current document count: 290\n",
      "Processing batch 30, size: 10\n",
      "Current document count: 300\n",
      "Processing batch 31, size: 10\n",
      "Current document count: 310\n",
      "Processing batch 32, size: 10\n",
      "Current document count: 320\n",
      "Processing batch 33, size: 10\n",
      "Current document count: 330\n",
      "Processing batch 34, size: 10\n",
      "Current document count: 340\n",
      "Processing batch 35, size: 10\n",
      "Current document count: 350\n",
      "Processing batch 36, size: 10\n",
      "Current document count: 360\n",
      "Processing batch 37, size: 10\n",
      "Current document count: 370\n",
      "Processing batch 38, size: 10\n",
      "Current document count: 380\n",
      "Processing batch 39, size: 10\n",
      "Current document count: 390\n",
      "Processing batch 40, size: 10\n",
      "Current document count: 400\n",
      "Processing batch 41, size: 10\n",
      "Current document count: 410\n",
      "Processing batch 42, size: 10\n",
      "Current document count: 420\n",
      "Processing batch 43, size: 10\n",
      "Current document count: 430\n",
      "Processing batch 44, size: 10\n",
      "Current document count: 440\n",
      "Processing batch 45, size: 10\n",
      "Current document count: 450\n",
      "Processing batch 46, size: 10\n",
      "Current document count: 460\n",
      "Processing batch 47, size: 10\n",
      "Current document count: 470\n",
      "Processing batch 48, size: 10\n",
      "Current document count: 480\n",
      "Processing batch 49, size: 10\n",
      "Current document count: 490\n",
      "Processing batch 50, size: 10\n",
      "Current document count: 500\n",
      "Processing batch 51, size: 10\n",
      "Current document count: 510\n",
      "Processing batch 52, size: 10\n",
      "Current document count: 520\n",
      "Processing batch 53, size: 5\n",
      "Current document count: 525\n",
      "Collection count: 525\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(\"../job_profiles_db\")\n",
    "collection = client.get_or_create_collection(\"job_profiles\",metadata={\"hnsw:batch_size\":10000})\n",
    "\n",
    "def create_vectorstore_with_batching(documents, batch_size=10):  # Reduced batch size\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    vectorstore = Chroma(\n",
    "        # persist_directory=\"job_profiles_db\",\n",
    "        client=client,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=\"job_profiles\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        for i in range(0, len(documents), batch_size):\n",
    "            batch = documents[i:i + batch_size]\n",
    "            print(f\"Processing batch {i//batch_size + 1}, size: {len(batch)}\")\n",
    "            \n",
    "            vectorstore.add_documents(documents=batch)\n",
    "            \n",
    "            # Add verification step\n",
    "            current_count = vectorstore._collection.count()\n",
    "            print(f\"Current document count: {current_count}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {str(e)}\")\n",
    "        \n",
    "    return vectorstore\n",
    "\n",
    "loader = CSVLoader(file_path=\"../data/job profiles/2025-02-07_profiles.csv\", content_columns=[\"title\", \"overview\"], encoding=\"utf-8-sig\")\n",
    "documents = loader.load()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Documents adding: {len(chunks)}\")\n",
    "print('creating vector store..')\n",
    "vectorstore = create_vectorstore_with_batching(chunks)\n",
    "\n",
    "print(f\"Collection count: {vectorstore._collection.count()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job-profiles-rag-jjdb_p5q-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
